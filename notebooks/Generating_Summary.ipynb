{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eaef2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition, manifold\n",
    "from matplotlib import cm\n",
    "import scipy.io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from scipy.stats import ortho_group\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.ops.rnn_cell_impl import RNNCell\n",
    "import tensorflow.keras.backend as K\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0723f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_arr = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    diag1_arr = []\n",
    "    diag2_arr = []\n",
    "    for acc in [60,80,95]:\n",
    "        destination_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_512/n_hidden_256/weight_matrix/acc_%s'%acc\n",
    "        model_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_512/n_hidden_256/2_stim_batch_size_512_n_hidden_256_acc_%s_seed_%s_with_noise'%(acc,i)\n",
    "        isomap_folder = model_folder+'/isomap'\n",
    "        isomap_stim1_file = isomap_folder+'/trained_delay2_hidden_target_isomap.png'\n",
    "        if os.path.exists(isomap_stim1_file):\n",
    "            with open(os.path.join(model_folder, 'results.json')) as f:\n",
    "                results_dict = json.load(f)\n",
    "                diag1_arr.append(results_dict['delay 2 diag 1'])\n",
    "                diag2_arr.append(results_dict['delay 2 diag 2'])\n",
    "    diag_arr.append([diag1_arr,diag2_arr])\n",
    "diag_arr = np.array(diag_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c62bb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag1_df = pd.DataFrame(diag_arr[:,0,:], index=np.arange(1,21), columns=['acc=60','acc=80','acc=95'])\n",
    "diag1_df['increasing diagonal'] = np.logical_and(diag1_df.iloc[:,0]<diag1_df.iloc[:,1],diag1_df.iloc[:,1]<diag1_df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "71034a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2_df = pd.DataFrame(diag_arr[:,1,:], index=np.arange(1,21), columns=['acc=60','acc=80','acc=95'])\n",
    "diag2_df['increasing diagonal'] = np.logical_and(diag2_df.iloc[:,0]<diag1_df.iloc[:,1],diag1_df.iloc[:,1]<diag2_df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "094065d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag1_df['torus'] = [True]*20\n",
    "for i in [1,3,4,5,6,11,20]:\n",
    "    diag1_df['torus'][i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e7b74542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc=60</th>\n",
       "      <th>acc=80</th>\n",
       "      <th>acc=95</th>\n",
       "      <th>increasing diagonal</th>\n",
       "      <th>torus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.067008</td>\n",
       "      <td>0.166887</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.199770</td>\n",
       "      <td>0.154172</td>\n",
       "      <td>0.117645</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032093</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.119128</td>\n",
       "      <td>0.052725</td>\n",
       "      <td>0.049260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.140820</td>\n",
       "      <td>0.186549</td>\n",
       "      <td>0.216735</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.232626</td>\n",
       "      <td>0.193791</td>\n",
       "      <td>0.152794</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.135701</td>\n",
       "      <td>0.039146</td>\n",
       "      <td>0.102120</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.140375</td>\n",
       "      <td>0.154435</td>\n",
       "      <td>0.176401</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.173330</td>\n",
       "      <td>0.139085</td>\n",
       "      <td>0.176584</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.076571</td>\n",
       "      <td>0.067246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.110130</td>\n",
       "      <td>0.115384</td>\n",
       "      <td>0.195636</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.243069</td>\n",
       "      <td>0.207496</td>\n",
       "      <td>0.130179</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.157691</td>\n",
       "      <td>0.163730</td>\n",
       "      <td>0.129222</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.090831</td>\n",
       "      <td>0.088033</td>\n",
       "      <td>0.170583</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.031458</td>\n",
       "      <td>0.110192</td>\n",
       "      <td>0.151027</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.095463</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>0.081946</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.209947</td>\n",
       "      <td>0.209109</td>\n",
       "      <td>0.100836</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.092408</td>\n",
       "      <td>0.227378</td>\n",
       "      <td>0.199977</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.086432</td>\n",
       "      <td>0.082729</td>\n",
       "      <td>0.102523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc=60    acc=80    acc=95  increasing diagonal  torus\n",
       "1   0.052900  0.067008  0.166887                 True  False\n",
       "2   0.199770  0.154172  0.117645                False   True\n",
       "3   0.038942       NaN  0.032093                False  False\n",
       "4   0.119128  0.052725  0.049260                False  False\n",
       "5   0.140820  0.186549  0.216735                 True  False\n",
       "6   0.232626  0.193791  0.152794                False  False\n",
       "7   0.135701  0.039146  0.102120                False   True\n",
       "8   0.140375  0.154435  0.176401                 True   True\n",
       "9   0.173330  0.139085  0.176584                False   True\n",
       "10  0.077316  0.076571  0.067246                False   True\n",
       "11  0.110130  0.115384  0.195636                 True  False\n",
       "12  0.243069  0.207496  0.130179                False   True\n",
       "13  0.157691  0.163730  0.129222                False   True\n",
       "14  0.090831  0.088033  0.170583                False   True\n",
       "15  0.031458  0.110192  0.151027                 True   True\n",
       "16  0.095463  0.094274  0.081946                False   True\n",
       "17  0.209947  0.209109  0.100836                False   True\n",
       "18  0.092408  0.227378  0.199977                False   True\n",
       "19  0.086432  0.082729  0.102523                False   True\n",
       "20       NaN       NaN  0.079773                False  False"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "74ac110e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/5ndpkbgn4sz_h0t8471c9kqr0000gn/T/ipykernel_48554/4149869660.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diag2_df['torus'][i] = False\n"
     ]
    }
   ],
   "source": [
    "diag2_df['torus'] = [True]*20\n",
    "for i in [1,3,4,5,6,11,20]:\n",
    "    diag2_df['torus'][i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d42e5ba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc=60</th>\n",
       "      <th>acc=80</th>\n",
       "      <th>acc=95</th>\n",
       "      <th>increasing diagonal</th>\n",
       "      <th>torus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098359</td>\n",
       "      <td>0.119585</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236600</td>\n",
       "      <td>0.245906</td>\n",
       "      <td>0.168532</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.156832</td>\n",
       "      <td>0.245458</td>\n",
       "      <td>0.183230</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260513</td>\n",
       "      <td>0.203095</td>\n",
       "      <td>0.144948</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.184171</td>\n",
       "      <td>0.331074</td>\n",
       "      <td>0.118155</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079421</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.087605</td>\n",
       "      <td>0.154421</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.164591</td>\n",
       "      <td>0.124051</td>\n",
       "      <td>0.053850</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.159317</td>\n",
       "      <td>0.134482</td>\n",
       "      <td>0.149289</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.142291</td>\n",
       "      <td>0.196571</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.290878</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>0.115583</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276380</td>\n",
       "      <td>0.208508</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.206945</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>0.182539</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.126386</td>\n",
       "      <td>0.143476</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.228017</td>\n",
       "      <td>0.065424</td>\n",
       "      <td>0.276135</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.195442</td>\n",
       "      <td>0.167731</td>\n",
       "      <td>0.136403</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.174880</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.217306</td>\n",
       "      <td>0.158323</td>\n",
       "      <td>0.146246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.059585</td>\n",
       "      <td>0.036262</td>\n",
       "      <td>0.028631</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.121268</td>\n",
       "      <td>0.051139</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc=60    acc=80    acc=95  increasing diagonal  torus\n",
       "1        NaN  0.098359  0.119585                False  False\n",
       "2   0.236600  0.245906  0.168532                False   True\n",
       "3   0.156832  0.245458  0.183230                False  False\n",
       "4   0.260513  0.203095  0.144948                False  False\n",
       "5   0.184171  0.331074  0.118155                False  False\n",
       "6        NaN       NaN  0.079421                False  False\n",
       "7   0.087605  0.154421  0.100199                False   True\n",
       "8   0.164591  0.124051  0.053850                False   True\n",
       "9   0.159317  0.134482  0.149289                False   True\n",
       "10  0.142291  0.196571  0.119616                False   True\n",
       "11  0.290878  0.238763  0.115583                False  False\n",
       "12       NaN  0.276380  0.208508                False   True\n",
       "13  0.206945  0.142960  0.182539                False   True\n",
       "14  0.126386  0.143476  0.107472                False   True\n",
       "15  0.228017  0.065424  0.276135                False   True\n",
       "16  0.195442  0.167731  0.136403                False   True\n",
       "17       NaN  0.174880  0.065444                False   True\n",
       "18  0.217306  0.158323  0.146246                False   True\n",
       "19  0.059585  0.036262  0.028631                False   True\n",
       "20  0.152416  0.121268  0.051139                False  False"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06986c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d27840cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_arr = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    diag1_arr = []\n",
    "    diag2_arr = []\n",
    "    for acc in [60,80,95]:\n",
    "        destination_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_512/n_hidden_128/weight_matrix/acc_%s'%acc\n",
    "        model_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_512/n_hidden_128/2_stim_batch_size_512_n_hidden_128_acc_%s_seed_%s_with_noise'%(acc,i)\n",
    "        isomap_folder = model_folder+'/isomap'\n",
    "        isomap_stim1_file = isomap_folder+'/trained_delay2_hidden_target_isomap.png'\n",
    "        if os.path.exists(isomap_stim1_file):\n",
    "            with open(os.path.join(model_folder, 'results.json')) as f:\n",
    "                results_dict = json.load(f)\n",
    "                diag1_arr.append(results_dict['delay 2 diag 1'])\n",
    "                diag2_arr.append(results_dict['delay 2 diag 2'])\n",
    "    diag_arr.append([diag1_arr,diag2_arr])\n",
    "diag_arr = np.array(diag_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1c901fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag1_df = pd.DataFrame(diag_arr[:,0,:], index=np.arange(1,21), columns=['acc=60','acc=80','acc=95'])\n",
    "diag1_df['increasing diagonal'] = np.logical_and(diag1_df.iloc[:,0]<diag1_df.iloc[:,1],diag1_df.iloc[:,1]<diag1_df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61ed1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2_df = pd.DataFrame(diag_arr[:,1,:], index=np.arange(1,21), columns=['acc=60','acc=80','acc=95'])\n",
    "diag2_df['increasing diagonal'] = np.logical_and(diag2_df.iloc[:,0]<diag1_df.iloc[:,1],diag1_df.iloc[:,1]<diag2_df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d1c41314",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag1_df['torus'] = [True]*20\n",
    "for i in [1,3,4,5,6,11,20]:\n",
    "    diag1_df['torus'][i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "21ffdf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc=60</th>\n",
       "      <th>acc=80</th>\n",
       "      <th>acc=95</th>\n",
       "      <th>increasing diagonal</th>\n",
       "      <th>torus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.067008</td>\n",
       "      <td>0.166887</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.199770</td>\n",
       "      <td>0.154172</td>\n",
       "      <td>0.117645</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032093</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.119128</td>\n",
       "      <td>0.052725</td>\n",
       "      <td>0.049260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.140820</td>\n",
       "      <td>0.186549</td>\n",
       "      <td>0.216735</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.232626</td>\n",
       "      <td>0.193791</td>\n",
       "      <td>0.152794</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.135701</td>\n",
       "      <td>0.039146</td>\n",
       "      <td>0.102120</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.140375</td>\n",
       "      <td>0.154435</td>\n",
       "      <td>0.176401</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.173330</td>\n",
       "      <td>0.139085</td>\n",
       "      <td>0.176584</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.076571</td>\n",
       "      <td>0.067246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.110130</td>\n",
       "      <td>0.115384</td>\n",
       "      <td>0.195636</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.243069</td>\n",
       "      <td>0.207496</td>\n",
       "      <td>0.130179</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.157691</td>\n",
       "      <td>0.163730</td>\n",
       "      <td>0.129222</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.090831</td>\n",
       "      <td>0.088033</td>\n",
       "      <td>0.170583</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.031458</td>\n",
       "      <td>0.110192</td>\n",
       "      <td>0.151027</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.095463</td>\n",
       "      <td>0.094274</td>\n",
       "      <td>0.081946</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.209947</td>\n",
       "      <td>0.209109</td>\n",
       "      <td>0.100836</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.092408</td>\n",
       "      <td>0.227378</td>\n",
       "      <td>0.199977</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.086432</td>\n",
       "      <td>0.082729</td>\n",
       "      <td>0.102523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc=60    acc=80    acc=95  increasing diagonal  torus\n",
       "1   0.052900  0.067008  0.166887                 True  False\n",
       "2   0.199770  0.154172  0.117645                False   True\n",
       "3   0.038942       NaN  0.032093                False  False\n",
       "4   0.119128  0.052725  0.049260                False  False\n",
       "5   0.140820  0.186549  0.216735                 True  False\n",
       "6   0.232626  0.193791  0.152794                False  False\n",
       "7   0.135701  0.039146  0.102120                False   True\n",
       "8   0.140375  0.154435  0.176401                 True   True\n",
       "9   0.173330  0.139085  0.176584                False   True\n",
       "10  0.077316  0.076571  0.067246                False   True\n",
       "11  0.110130  0.115384  0.195636                 True  False\n",
       "12  0.243069  0.207496  0.130179                False   True\n",
       "13  0.157691  0.163730  0.129222                False   True\n",
       "14  0.090831  0.088033  0.170583                False   True\n",
       "15  0.031458  0.110192  0.151027                 True   True\n",
       "16  0.095463  0.094274  0.081946                False   True\n",
       "17  0.209947  0.209109  0.100836                False   True\n",
       "18  0.092408  0.227378  0.199977                False   True\n",
       "19  0.086432  0.082729  0.102523                False   True\n",
       "20       NaN       NaN  0.079773                False  False"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0621c6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/5ndpkbgn4sz_h0t8471c9kqr0000gn/T/ipykernel_48554/4149869660.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diag2_df['torus'][i] = False\n"
     ]
    }
   ],
   "source": [
    "diag2_df['torus'] = [True]*20\n",
    "for i in [1,3,4,5,6,11,20]:\n",
    "    diag2_df['torus'][i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bb186cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc=60</th>\n",
       "      <th>acc=80</th>\n",
       "      <th>acc=95</th>\n",
       "      <th>increasing diagonal</th>\n",
       "      <th>torus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098359</td>\n",
       "      <td>0.119585</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236600</td>\n",
       "      <td>0.245906</td>\n",
       "      <td>0.168532</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.156832</td>\n",
       "      <td>0.245458</td>\n",
       "      <td>0.183230</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260513</td>\n",
       "      <td>0.203095</td>\n",
       "      <td>0.144948</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.184171</td>\n",
       "      <td>0.331074</td>\n",
       "      <td>0.118155</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079421</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.087605</td>\n",
       "      <td>0.154421</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.164591</td>\n",
       "      <td>0.124051</td>\n",
       "      <td>0.053850</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.159317</td>\n",
       "      <td>0.134482</td>\n",
       "      <td>0.149289</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.142291</td>\n",
       "      <td>0.196571</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.290878</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>0.115583</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276380</td>\n",
       "      <td>0.208508</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.206945</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>0.182539</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.126386</td>\n",
       "      <td>0.143476</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.228017</td>\n",
       "      <td>0.065424</td>\n",
       "      <td>0.276135</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.195442</td>\n",
       "      <td>0.167731</td>\n",
       "      <td>0.136403</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.174880</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.217306</td>\n",
       "      <td>0.158323</td>\n",
       "      <td>0.146246</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.059585</td>\n",
       "      <td>0.036262</td>\n",
       "      <td>0.028631</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.152416</td>\n",
       "      <td>0.121268</td>\n",
       "      <td>0.051139</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc=60    acc=80    acc=95  increasing diagonal  torus\n",
       "1        NaN  0.098359  0.119585                False  False\n",
       "2   0.236600  0.245906  0.168532                False   True\n",
       "3   0.156832  0.245458  0.183230                False  False\n",
       "4   0.260513  0.203095  0.144948                False  False\n",
       "5   0.184171  0.331074  0.118155                False  False\n",
       "6        NaN       NaN  0.079421                False  False\n",
       "7   0.087605  0.154421  0.100199                False   True\n",
       "8   0.164591  0.124051  0.053850                False   True\n",
       "9   0.159317  0.134482  0.149289                False   True\n",
       "10  0.142291  0.196571  0.119616                False   True\n",
       "11  0.290878  0.238763  0.115583                False  False\n",
       "12       NaN  0.276380  0.208508                False   True\n",
       "13  0.206945  0.142960  0.182539                False   True\n",
       "14  0.126386  0.143476  0.107472                False   True\n",
       "15  0.228017  0.065424  0.276135                False   True\n",
       "16  0.195442  0.167731  0.136403                False   True\n",
       "17       NaN  0.174880  0.065444                False   True\n",
       "18  0.217306  0.158323  0.146246                False   True\n",
       "19  0.059585  0.036262  0.028631                False   True\n",
       "20  0.152416  0.121268  0.051139                False  False"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17358116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1bb04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_arr = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    diag1_arr = []\n",
    "    diag2_arr = []\n",
    "    for acc in [60,80,95]:\n",
    "        destination_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_512/n_hidden_128/weight_matrix/acc_%s'%acc\n",
    "        model_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_512/n_hidden_128/2_stim_batch_size_512_n_hidden_128_acc_%s_seed_%s_with_noise'%(acc,i)\n",
    "        isomap_folder = model_folder+'/isomap'\n",
    "        isomap_stim1_file = isomap_folder+'/trained_delay2_hidden_target_isomap.png'\n",
    "        if os.path.exists(isomap_stim1_file):\n",
    "            with open(os.path.join(model_folder, 'results.json')) as f:\n",
    "                results_dict = json.load(f)\n",
    "                diag1_arr.append(results_dict['delay 2 diag 1'])\n",
    "                diag2_arr.append(results_dict['delay 2 diag 2'])\n",
    "        else:\n",
    "                diag1_arr.append(np.nan)\n",
    "                diag2_arr.append(np.nan)\n",
    "    diag_arr.append([diag1_arr,diag2_arr])\n",
    "diag_arr = np.array(diag_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a40a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag1_df = pd.DataFrame(diag_arr[:,0,:], index=np.arange(1,21), columns=['acc=60','acc=80','acc=95'])\n",
    "diag1_df['increasing diagonal'] = np.logical_and(diag1_df.iloc[:,0]<diag1_df.iloc[:,1],diag1_df.iloc[:,1]<diag1_df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6350e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag2_df = pd.DataFrame(diag_arr[:,1,:], index=np.arange(1,21), columns=['acc=60','acc=80','acc=95'])\n",
    "diag2_df['increasing diagonal'] = np.logical_and(diag2_df.iloc[:,0]<diag1_df.iloc[:,1],diag1_df.iloc[:,1]<diag2_df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83fbb6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/5ndpkbgn4sz_h0t8471c9kqr0000gn/T/ipykernel_4863/3259295890.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diag1_df['torus'][i] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc=60</th>\n",
       "      <th>acc=80</th>\n",
       "      <th>acc=95</th>\n",
       "      <th>increasing diagonal</th>\n",
       "      <th>torus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.057892</td>\n",
       "      <td>0.071604</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.191621</td>\n",
       "      <td>0.183838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>-0.021365</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.170249</td>\n",
       "      <td>0.161036</td>\n",
       "      <td>0.205461</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.094581</td>\n",
       "      <td>0.117519</td>\n",
       "      <td>0.143493</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.135075</td>\n",
       "      <td>0.196024</td>\n",
       "      <td>0.172265</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052415</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117207</td>\n",
       "      <td>0.192616</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111183</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.094983</td>\n",
       "      <td>0.026580</td>\n",
       "      <td>0.122286</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.017034</td>\n",
       "      <td>0.053707</td>\n",
       "      <td>0.027992</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250229</td>\n",
       "      <td>0.074208</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.121401</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>0.081441</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047315</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.122588</td>\n",
       "      <td>0.061516</td>\n",
       "      <td>0.118134</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.044435</td>\n",
       "      <td>-0.009897</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.161114</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc=60    acc=80    acc=95  increasing diagonal  torus\n",
       "1   0.018555  0.057892  0.071604                 True  False\n",
       "2   0.191621  0.183838       NaN                False   True\n",
       "3        NaN  0.002863 -0.021365                False   True\n",
       "4        NaN -0.034486       NaN                False   True\n",
       "5   0.170249  0.161036  0.205461                False  False\n",
       "6        NaN       NaN       NaN                False   True\n",
       "7   0.094581  0.117519  0.143493                 True   True\n",
       "8   0.135075  0.196024  0.172265                False   True\n",
       "9        NaN       NaN       NaN                False  False\n",
       "10       NaN  0.052415 -0.002555                False  False\n",
       "11       NaN  0.117207  0.192616                False   True\n",
       "12       NaN       NaN  0.111183                False  False\n",
       "13  0.094983  0.026580  0.122286                False   True\n",
       "14  0.017034  0.053707  0.027992                False   True\n",
       "15       NaN  0.250229  0.074208                False  False\n",
       "16  0.121401  0.043889  0.081441                False   True\n",
       "17       NaN       NaN  0.047315                False  False\n",
       "18  0.122588  0.061516  0.118134                False  False\n",
       "19  0.044435 -0.009897  0.010626                False  False\n",
       "20  0.161114  0.113971       NaN                False  False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag1_df['torus'] = [True]*20\n",
    "for i in [1,5,9,10,12,15,17,18,19,20]:\n",
    "    diag1_df['torus'][i] = False\n",
    "diag1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95cdd7d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/5ndpkbgn4sz_h0t8471c9kqr0000gn/T/ipykernel_4863/490122443.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diag2_df['torus'][i] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc=60</th>\n",
       "      <th>acc=80</th>\n",
       "      <th>acc=95</th>\n",
       "      <th>increasing diagonal</th>\n",
       "      <th>torus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049182</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>-0.002103</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068639</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098783</td>\n",
       "      <td>0.074637</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.071018</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.200545</td>\n",
       "      <td>0.069949</td>\n",
       "      <td>0.018367</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.068314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061445</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039508</td>\n",
       "      <td>0.183041</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.090256</td>\n",
       "      <td>0.141922</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148396</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138475</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164647</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.239117</td>\n",
       "      <td>0.348330</td>\n",
       "      <td>0.147982</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.062533</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.087553</td>\n",
       "      <td>0.102825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139445</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.049126</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.033412</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.126039</td>\n",
       "      <td>0.142367</td>\n",
       "      <td>0.189991</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053103</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc=60    acc=80    acc=95  increasing diagonal  torus\n",
       "1   0.049182  0.003403 -0.002103                False  False\n",
       "2   0.026931       NaN  0.068639                False   True\n",
       "3        NaN       NaN  0.010609                False   True\n",
       "4        NaN  0.098783  0.074637                False   True\n",
       "5        NaN  0.003688  0.071018                False  False\n",
       "6   0.200545  0.069949  0.018367                False   True\n",
       "7   0.068314       NaN  0.061445                False   True\n",
       "8   0.039508  0.183041  0.010679                False   True\n",
       "9        NaN  0.090256  0.141922                False  False\n",
       "10       NaN       NaN  0.148396                False  False\n",
       "11       NaN  0.138475  0.083774                False   True\n",
       "12       NaN  0.164647  0.012527                False  False\n",
       "13  0.239117  0.348330  0.147982                False   True\n",
       "14  0.062533  0.055500 -0.002199                False   True\n",
       "15  0.087553  0.102825       NaN                False  False\n",
       "16  0.016979       NaN  0.139445                 True   True\n",
       "17  0.049126  0.018410  0.033412                False  False\n",
       "18  0.126039  0.142367  0.189991                False  False\n",
       "19       NaN       NaN  0.053103                False  False\n",
       "20  0.003665  0.022232       NaN                False  False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag2_df['torus'] = [True]*20\n",
    "for i in [1,5,9,10,12,15,17,18,19,20]:\n",
    "    diag2_df['torus'][i] = False\n",
    "diag2_df\n",
    "diag2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5824e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f68317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7717d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition, manifold\n",
    "from matplotlib import cm\n",
    "import scipy.io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from scipy.stats import ortho_group\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.ops.rnn_cell_impl import RNNCell\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "n_eachring = 32\n",
    "n_input, n_output = 1+n_eachring, 1+n_eachring\n",
    "batch_size_train = 64\n",
    "hp = {\n",
    "        # batch size for training\n",
    "        'batch_size_train': batch_size_train,\n",
    "        # batch size for validation\n",
    "        'batch_size_val': batch_size_train,\n",
    "        # Type of loss functions\n",
    "        'loss_type': 'lsq',\n",
    "        # Optimizer\n",
    "        'optimizer': 'adam',\n",
    "        # Type of activation runctions, relu, softplus, tanh, elu\n",
    "        'activation': 'relu',\n",
    "        # Time constant (ms)\n",
    "        'tau': 100,\n",
    "        # discretization time step (ms)\n",
    "        'dt': 20,\n",
    "        # discretization time step/time constant\n",
    "        'alpha': 0.2,\n",
    "        # recurrent noise\n",
    "#         'sigma_rec': 0.05,\n",
    "        'sigma_rec': 0,\n",
    "        # input noise\n",
    "#         'sigma_x': 0.01,\n",
    "        'sigma_x': 0,\n",
    "        # leaky_rec weight initialization, diag, randortho, randgauss\n",
    "        'w_rec_init': 'randortho',\n",
    "        # a default weak regularization prevents instability\n",
    "        'l1_h': 0,\n",
    "        # l2 regularization on activity\n",
    "        'l2_h': 0,\n",
    "        # l2 regularization on weight\n",
    "        'l1_weight': 0,\n",
    "        # l2 regularization on weight\n",
    "        'l2_weight': 0,\n",
    "        # l2 regularization on deviation from initialization\n",
    "        'l2_weight_init': 0,\n",
    "        # Stopping performance\n",
    "        'target_perf': 1.,\n",
    "        # number of units each ring\n",
    "        'n_eachring': n_eachring,\n",
    "        # first input index for rule units\n",
    "        'rule_start': 1+n_eachring,\n",
    "        # number of input units\n",
    "        'n_input': n_input,\n",
    "        # number of output units\n",
    "        'n_output': n_output,\n",
    "        # number of recurrent units\n",
    "        'n_rnn': 256,\n",
    "        # learning rate\n",
    "        'learning_rate': 0.0001,\n",
    "        # number of display epochs\n",
    "        'steps_per_epoch': 1,\n",
    "        # number of fixed locations for isomap\n",
    "        'n_loc': 128,\n",
    "        # accuracy threshold to stop training\n",
    "        'accuracy_threshold': 0.9,\n",
    "        }\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "n_loc = 128\n",
    "n_stim_loc1, n_stim_loc2, repeat = stim_loc_shape = n_loc, n_loc, 1\n",
    "stim_loc_size = np.prod(stim_loc_shape)\n",
    "ind_stim_loc1, ind_stim_loc2, ind_repeat = np.unravel_index(range(stim_loc_size),stim_loc_shape)\n",
    "stim1_locs = 2*np.pi*ind_stim_loc1/n_stim_loc1\n",
    "stim2_locs = 2*np.pi*ind_stim_loc2/n_stim_loc2\n",
    "\n",
    "palette1 = cm.get_cmap('autumn',n_loc+15)\n",
    "palette1 = [palette1(i)[:3] for i in range(n_loc)]\n",
    "palette2 = cm.get_cmap('summer',n_loc+15)\n",
    "palette2 = [palette2(i)[:3] for i in range(n_loc)]\n",
    "\n",
    "color1=np.array(palette1)[ind_stim_loc1]\n",
    "color2=np.array(palette2)[ind_stim_loc2]\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "class LeakyRNNCell2(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,hp,**kwargs):\n",
    "\n",
    "        self.units = hp['n_rnn']\n",
    "        self.state_size = hp['n_rnn']\n",
    "        \n",
    "        activation = hp['activation']\n",
    "        if activation == 'softplus':\n",
    "            self._activation = tf.nn.softplus\n",
    "            self._w_in_start = 1.0\n",
    "            self._w_rec_start = 0.5\n",
    "        elif activation == 'tanh':\n",
    "            self._activation = tf.tanh\n",
    "            self._w_in_start = 1.0\n",
    "            self._w_rec_start = 1.0\n",
    "        elif activation == 'relu':\n",
    "            self._activation = tf.nn.relu\n",
    "            self._w_in_start = 1.0\n",
    "            self._w_rec_start = 0.5\n",
    "        elif activation == 'power':\n",
    "            self._activation = lambda x: tf.square(tf.nn.relu(x))\n",
    "            self._w_in_start = 1.0\n",
    "            self._w_rec_start = 0.01\n",
    "        elif activation == 'retanh':\n",
    "            self._activation = lambda x: tf.tanh(tf.nn.relu(x))\n",
    "            self._w_in_start = 1.0\n",
    "            self._w_rec_start = 0.5\n",
    "        else:\n",
    "            raise ValueError('Unknown activation')\n",
    "            \n",
    "\n",
    "        self.rng = hp['rng']\n",
    "        self._alpha = hp['alpha']\n",
    "        self._sigma = np.sqrt(2 / self._alpha) * hp['sigma_rec']\n",
    "        \n",
    "        super(LeakyRNNCell2, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        w_in0 = (self.rng.randn(input_shape[-1], self.units) /\n",
    "                 np.sqrt(input_shape[-1]) * self._w_in_start)\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units), dtype=tf.float32,\n",
    "                                      initializer=tf.constant_initializer(w_in0),\n",
    "                                      name='kernel')\n",
    "        w_rec0 = self._w_rec_start*ortho_group.rvs(dim=self.units, random_state=self.rng)\n",
    "        self.recurrent_kernel = self.add_weight(shape=(self.units, self.units), dtype=tf.float32,\n",
    "                                                initializer=tf.constant_initializer(w_rec0),\n",
    "                                                name='recurrent_kernel')\n",
    "        matrix0 = np.concatenate((w_in0, w_rec0), axis=0)\n",
    "    \n",
    "#         self.kernel = self.add_weight(\n",
    "#                 name='kernel',\n",
    "#                 shape=[input_shape[-1] + self.units, self.units], \n",
    "#                 dtype=tf.float32,\n",
    "#                 initializer=tf.constant_initializer(matrix0))\n",
    "        \n",
    "        self._bias = self.add_weight(\n",
    "                name='bias',\n",
    "                shape=[self.units],\n",
    "                dtype=tf.float32,\n",
    "                initializer=tf.zeros_initializer())\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "#         h = tf.keras.backend.dot(array_ops.concat([inputs, prev_output], 1), self.kernel)\n",
    "        h = tf.keras.backend.dot(inputs, self.kernel)\n",
    "        h = h + tf.keras.backend.dot(prev_output, self.recurrent_kernel)\n",
    "        h = tf.nn.bias_add(h, self._bias)\n",
    "        noise = tf.random.normal(tf.shape(prev_output), mean=0, stddev=self._sigma)\n",
    "        h = h + noise\n",
    "        output = self._activation(h)\n",
    "        output = (1-self._alpha) * prev_output + self._alpha * output\n",
    "        return output, [output]\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def get_dist(original_dist):\n",
    "    '''Get the distance in periodic boundary conditions'''\n",
    "    return np.minimum(abs(original_dist),2*np.pi-abs(original_dist))\n",
    "\n",
    "class Trial(object):\n",
    "    \"\"\"Class representing a batch of trials.\"\"\"\n",
    "\n",
    "    def __init__(self, config, tdim, batch_size):\n",
    "        \"\"\"A batch of trials.\n",
    "\n",
    "        Args:\n",
    "            config: dictionary of configurations\n",
    "            tdim: int, number of time steps\n",
    "            batch_size: int, batch size\n",
    "        \"\"\"\n",
    "        self.float_type = 'float32' # This should be the default\n",
    "        self.config = config\n",
    "        self.dt = self.config['dt']\n",
    "\n",
    "        self.n_eachring = self.config['n_eachring']\n",
    "        self.n_input = self.config['n_input']\n",
    "        self.n_output = self.config['n_output']\n",
    "        self.pref  = np.arange(0,2*np.pi,2*np.pi/self.n_eachring) # preferences\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tdim = tdim\n",
    "        self.x = np.zeros((tdim, batch_size, self.n_input), dtype=self.float_type)\n",
    "        self.y = np.zeros((tdim, batch_size, self.n_output), dtype=self.float_type)\n",
    "        if self.config['loss_type'] == 'lsq':\n",
    "            self.y[:,:,:] = 0.05\n",
    "        # y_loc is the stimulus location of the output, -1 for fixation, (0,2 pi) for response\n",
    "        self.y_loc = -np.ones((tdim, batch_size)      , dtype=self.float_type)\n",
    "\n",
    "        self._sigma_x = config['sigma_x']*np.sqrt(2/config['alpha'])\n",
    "\n",
    "    def expand(self, var):\n",
    "        \"\"\"Expand an int/float to list.\"\"\"\n",
    "        if not hasattr(var, '__iter__'):\n",
    "            var = [var] * self.batch_size\n",
    "        return var\n",
    "\n",
    "    def add(self, loc_type, locs=None, ons=None, offs=None, strengths=1, mods=None):\n",
    "        \"\"\"Add an input or stimulus output.\n",
    "\n",
    "        Args:\n",
    "            loc_type: str (fix_in, stim, fix_out, out), type of information to be added\n",
    "            locs: array of list of float (batch_size,), locations to be added, only for loc_type=stim or out\n",
    "            ons: int or list, index of onset time\n",
    "            offs: int or list, index of offset time\n",
    "            strengths: float or list, strength of input or target output\n",
    "            mods: int or list, modalities of input or target output\n",
    "        \"\"\"\n",
    "\n",
    "        ons = self.expand(ons)\n",
    "        offs = self.expand(offs)\n",
    "        strengths = self.expand(strengths)\n",
    "        mods = self.expand(mods)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            if loc_type == 'fix_in':\n",
    "                self.x[ons[i]: offs[i], i, 0] = 1\n",
    "            elif loc_type == 'stim':\n",
    "                # Assuming that mods[i] starts from 1\n",
    "                self.x[ons[i]: offs[i], i, 1+(mods[i]-1)*self.n_eachring:1+mods[i]*self.n_eachring]                     += self.add_x_loc(locs[i])*strengths[i]\n",
    "            elif loc_type == 'fix_out':\n",
    "                # Notice this shouldn't be set at 1, because the output is logistic and saturates at 1\n",
    "                if self.config['loss_type'] == 'lsq':\n",
    "                    self.y[ons[i]: offs[i], i, 0] = 0.8\n",
    "                else:\n",
    "                    self.y[ons[i]: offs[i], i, 0] = 1.0\n",
    "            elif loc_type == 'out':\n",
    "                if self.config['loss_type'] == 'lsq':\n",
    "                    self.y[ons[i]: offs[i], i, 1:] += self.add_y_loc(locs[i])*strengths[i]  #target response\n",
    "                else:\n",
    "                    y_tmp = self.add_y_loc(locs[i])\n",
    "                    y_tmp /= np.sum(y_tmp)\n",
    "                    self.y[ons[i]: offs[i], i, 1:] += y_tmp\n",
    "                self.y_loc[ons[i]: offs[i], i] = locs[i] #location\n",
    "            else:\n",
    "                raise ValueError('Unknown loc_type')\n",
    "\n",
    "    def add_x_noise(self):\n",
    "        \"\"\"Add input noise.\"\"\"\n",
    "        self.x += self.config['rng'].randn(*self.x.shape)*self._sigma_x\n",
    "\n",
    "    def add_c_mask(self, pre_offs, post_ons):\n",
    "        \"\"\"Add a cost mask.\n",
    "\n",
    "        Usually there are two periods, pre and post response\n",
    "        Scale the mask weight for the post period so in total it's as important\n",
    "        as the pre period\n",
    "        \"\"\"\n",
    "\n",
    "        pre_on   = int(100/self.dt) # never check the first 100ms\n",
    "        pre_offs = self.expand(pre_offs)\n",
    "        post_ons = self.expand(post_ons)\n",
    "\n",
    "        if self.config['loss_type'] == 'lsq':\n",
    "            c_mask = np.zeros((self.tdim, self.batch_size, self.n_output), dtype=self.float_type)\n",
    "            for i in range(self.batch_size):\n",
    "                # Post response periods usually have the same length across tasks\n",
    "                c_mask[post_ons[i]:, i, :] = 5.\n",
    "                # Pre-response periods usually have different lengths across tasks\n",
    "                # To keep cost comparable across tasks\n",
    "                # Scale the cost mask of the pre-response period by a factor\n",
    "                c_mask[pre_on:pre_offs[i], i, :] = 1.\n",
    "\n",
    "            # self.c_mask[:, :, 0] *= self.n_eachring # Fixation is important\n",
    "            c_mask[:, :, 0] *= 2. # Fixation is important\n",
    "\n",
    "            self.c_mask = c_mask.reshape((self.tdim*self.batch_size, self.n_output))\n",
    "        else:\n",
    "            c_mask = np.zeros((self.tdim, self.batch_size), dtype=self.float_type)\n",
    "            for i in range(self.batch_size):\n",
    "                # Post response periods usually have the same length across tasks\n",
    "                # Having it larger than 1 encourages the network to achieve higher performance\n",
    "                c_mask[post_ons[i]:, i] = 5.\n",
    "                # Pre-response periods usually have different lengths across tasks\n",
    "                # To keep cost comparable across tasks\n",
    "                # Scale the cost mask of the pre-response period by a factor\n",
    "                c_mask[pre_on:pre_offs[i], i] = 1.\n",
    "\n",
    "            self.c_mask = c_mask.reshape((self.tdim*self.batch_size,))\n",
    "            self.c_mask /= self.c_mask.mean()\n",
    "\n",
    "    def add_rule(self, rule, on=None, off=None, strength=1.):\n",
    "        \"\"\"Add rule input.\"\"\"\n",
    "        if isinstance(rule, int):\n",
    "            self.x[on:off, :, self.config['rule_start']+rule] = strength\n",
    "        else:\n",
    "            ind_rule = get_rule_index(rule, self.config)\n",
    "            self.x[on:off, :, ind_rule] = strength\n",
    "\n",
    "    def add_x_loc(self, x_loc):\n",
    "        \"\"\"Input activity given location.\"\"\"\n",
    "        dist = get_dist(x_loc-self.pref)  # periodic boundary\n",
    "        dist /= np.pi/8\n",
    "        return 0.8*np.exp(-dist**2/2)\n",
    "\n",
    "    def add_y_loc(self, y_loc):\n",
    "        \"\"\"Target response given location.\"\"\"\n",
    "        dist = get_dist(y_loc-self.pref)  # periodic boundary\n",
    "        if self.config['loss_type'] == 'lsq':\n",
    "            dist /= np.pi/8\n",
    "            y = 0.8*np.exp(-dist**2/2)\n",
    "        else:\n",
    "            # One-hot output\n",
    "            y = np.zeros_like(dist)\n",
    "            ind = np.argmin(dist)\n",
    "            y[ind] = 1.\n",
    "        return y\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "\n",
    "def plot_loss_over_epochs(history, foldername=''):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(history.history['loss'],label=\"Training set loss\")\n",
    "    # plt.plot(history.history['val_loss'],label=\"Validation set loss\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('%sloss_over_epochs.png'%foldername)\n",
    "\n",
    "def get_delay_bins(delay):\n",
    "    dt=20\n",
    "    stim1_ons = int(500/dt)\n",
    "    stim1_offs = stim1_ons + int(300/dt)\n",
    "    stim2_ons =stim1_offs + int(1000/dt)\n",
    "    stim2_offs = stim2_ons + int(300/dt)\n",
    "    fix_offs  = stim2_offs + int(1000/dt)\n",
    "\n",
    "    baseline = (0,stim1_ons)\n",
    "\n",
    "    if delay == 1:\n",
    "            delay_bins = (stim2_ons - int(500/dt),stim2_ons)\n",
    "\n",
    "    elif delay == 2:\n",
    "            delay_bins = (fix_offs - int(500/dt),fix_offs)\n",
    "\n",
    "    return delay_bins\n",
    "\n",
    "def plot_tuning_curves(Z,foldername='',filename=''):\n",
    "    input\n",
    "    fig,ax = plt.subplots(min(Z.shape[1],10),1,figsize=(5,min(Z.shape[1],10)*3))\n",
    "    for i in range(min(Z.shape[1],10)):\n",
    "        if Z.shape[1]<10:\n",
    "            neuron = i\n",
    "        else:\n",
    "            neuron = i*int(Z.shape[1]/10)\n",
    "        for loc1 in [j*10 for j in range(int(128/10))]:\n",
    "            df = pd.DataFrame({'first_stim':ind_stim_loc1[ind_stim_loc1==loc1],'second_stim':ind_stim_loc2[ind_stim_loc1==loc1],'activity':Z[:,neuron][ind_stim_loc1==loc1]})\n",
    "            x = df['second_stim']\n",
    "            y = df['activity']\n",
    "            ax[i].scatter(x,y,s=1, color=palette1[loc1], label=loc1)\n",
    "        ax[i].set_ylabel('%dth neuron'%neuron, fontsize=13)\n",
    "    ax[0].legend(loc='upper left', bbox_to_anchor= (1.05, 1.05), title='Stim 1')\n",
    "    ax[0].set_xlabel('Stim 2', fontsize=13)\n",
    "    ax[0].xaxis.set_label_position('top') \n",
    "    if filename != '':\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(foldername+filename+'_stim2')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        \n",
    "    fig,ax = plt.subplots(min(Z.shape[1],10),1,figsize=(5,min(Z.shape[1],10)*3))\n",
    "    for i in range(min(Z.shape[1],10)):\n",
    "        if Z.shape[1]<10:\n",
    "            neuron = i\n",
    "        else:\n",
    "            neuron = i*int(Z.shape[1]/10)\n",
    "        for loc2 in [j*10 for j in range(int(128/10))]:\n",
    "            df = pd.DataFrame({'first_stim':ind_stim_loc1[ind_stim_loc2==loc2],'second_stim':ind_stim_loc2[ind_stim_loc2==loc2],'activity':Z[:,neuron][ind_stim_loc2==loc2]})\n",
    "            x = df['first_stim']\n",
    "            y = df['activity']\n",
    "            ax[i].scatter(x,y,s=1, color=palette2[loc2], label=loc2)\n",
    "        ax[i].set_ylabel('%dth neuron'%neuron, fontsize=13)\n",
    "    ax[0].legend(loc='upper left', bbox_to_anchor= (1.05, 1.05), title='Stim 2')\n",
    "    ax[0].set_xlabel('Stim 1', fontsize=13)\n",
    "    ax[0].xaxis.set_label_position('top') \n",
    "    if filename != '':\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(foldername+filename+'_stim1')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def fit_isomap(data_to_use, n_neighbors = 15, target_dim = 3):\n",
    "    iso_instance = manifold.Isomap(n_neighbors = n_neighbors, n_components = target_dim)\n",
    "    proj = iso_instance.fit_transform(data_to_use)\n",
    "    return proj\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    '''Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
    "    cubes as cubes, etc..  This is one possible solution to Matplotlib's\n",
    "    ax.set_aspect('equal') and ax.axis('equal') not working for 3D.\n",
    "\n",
    "    Input\n",
    "      ax: a matplotlib axis, e.g., as output from plt.gca().\n",
    "    '''\n",
    "\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    # The plot bounding box is a sphere in the sense of the infinity\n",
    "    # norm, hence I call half the max range the plot radius.\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n",
    "\n",
    "def plot_isomap(data_plot, color, annotate=False):\n",
    "    fig = plt.figure(figsize=(16,16),dpi=200)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    if annotate:\n",
    "        ax.scatter(data_plot[:,0], data_plot[:,1], data_plot[:,2], \n",
    "            s=5, alpha=1, edgecolor='face',c=color)\n",
    "        label = 0\n",
    "        for xyz in zip(data_plot[:,0], data_plot[:,1], data_plot[:,2]):\n",
    "            x, y, z = xyz\n",
    "            ax.text(x, y, z, '%s' % (label), size=5, zorder=1, color='k')\n",
    "            label += 1\n",
    "    else:\n",
    "        ax.scatter(data_plot[:,0], data_plot[:,1], data_plot[:,2], \n",
    "            s=20, alpha=1, edgecolor='face',c=color)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "    ax.xaxis.pane.set_edgecolor('w')\n",
    "    ax.yaxis.pane.set_edgecolor('w')\n",
    "    ax.zaxis.pane.set_edgecolor('w')\n",
    "    return fig, ax\n",
    "\n",
    "def plot_single_distractor_or_target(palette, xlim, ylim, zlim, label_plot, proj_plot, annotate=False, filename=''):\n",
    "\n",
    "    color=np.array(palette)[label_plot]\n",
    "\n",
    "    # h0_longest,h1_longest,h2_longest = run_ripser(proj_plot,figure_dir+'ripser'+figure_subscript)\n",
    "    fig, ax = plot_isomap(data_plot=proj_plot, color=color, annotate=annotate)\n",
    "    plt.setp(ax, xlim=xlim, ylim=ylim, zlim=zlim)\n",
    "    fig.tight_layout()\n",
    "    if filename is not None:\n",
    "        fig.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close(fig) \n",
    "\n",
    "\n",
    "def plot_all_isomap_figures(proj,foldername='',filename=''):\n",
    "    fig,ax = plot_isomap(data_plot=proj, color=color1)\n",
    "    set_axes_equal(ax)\n",
    "    fig.tight_layout()\n",
    "    if filename is not None:\n",
    "        fig.savefig(foldername+filename+'_target_isomap.png')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig,ax = plot_isomap(data_plot=proj, color=color2)\n",
    "    set_axes_equal(ax)\n",
    "    fig.tight_layout()\n",
    "    if filename is not None:\n",
    "        fig.savefig(foldername+filename+'_distractor_isomap.png')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    xlim=fig.gca().get_xlim()\n",
    "    ylim=fig.gca().get_ylim()\n",
    "    zlim=fig.gca().get_zlim()\n",
    "\n",
    "    num=0\n",
    "    indices = ind_stim_loc1==num\n",
    "    label_plot = ind_stim_loc2[indices]\n",
    "    proj_plot = proj[indices,:]\n",
    "    plot_single_distractor_or_target(palette = palette2, xlim = xlim, ylim = ylim, zlim = zlim, label_plot=label_plot, proj_plot = proj_plot, filename = foldername+filename+'_single_target.png')\n",
    "\n",
    "    num=0\n",
    "    indices = ind_stim_loc2==num\n",
    "    label_plot = ind_stim_loc1[indices]\n",
    "    proj_plot = proj[indices,:]\n",
    "    plot_single_distractor_or_target(palette = palette1, xlim = xlim, ylim = ylim, zlim = zlim, label_plot=label_plot, proj_plot = proj_plot, filename = foldername+filename+'_single_distractor.png')\n",
    "\n",
    "\n",
    "# In[109]:\n",
    "\n",
    "\n",
    "def get_c_mask(batch_dim):\n",
    "\n",
    "    dt = hp['dt']\n",
    "    pre_on   = int(100/dt)\n",
    "    \n",
    "    stim1_strengths = 1\n",
    "    stim2_strengths = 1\n",
    "    stim1_ons = int(500/dt)\n",
    "    stim1_offs = stim1_ons + int(300/dt)\n",
    "    stim2_ons =stim1_offs + int(1000/dt)\n",
    "    stim2_offs = stim2_ons + int(300/dt)\n",
    "    fix_offs  = stim2_offs + int(1000/dt)\n",
    "    output_2_on = fix_offs + int(500/dt)\n",
    "    tdim = output_2_on + int(500/dt)\n",
    "    check_ons = fix_offs + int(100/dt)\n",
    "    \n",
    "    pre_offs=fix_offs\n",
    "    post_ons=check_ons\n",
    "    \n",
    "    c_mask = np.zeros(batch_dim, dtype='float32')\n",
    "    for i in range(batch_dim[0]):\n",
    "        c_mask[i, post_ons:, :] = 5.\n",
    "        c_mask[i, pre_on:pre_offs, :] = 1.\n",
    "    c_mask[:, :, 0] *= 2. # Fixation is important\n",
    "    c_mask = c_mask.reshape((batch_dim[0]*batch_dim[1], batch_dim[2]))\n",
    "    \n",
    "    return c_mask\n",
    "    \n",
    "\n",
    "def custom_mse(y_true, y_hat):\n",
    "\n",
    "    n_output = hp['n_output']\n",
    "    y_true_shaped = tf.reshape(y_true, (-1, n_output))\n",
    "    y_hat_shaped = tf.reshape(y_hat, (-1, n_output))\n",
    "    c_mask_shaped = get_c_mask(y_true.shape)\n",
    "    cost_lsq = K.mean(K.square((y_true_shaped - y_hat_shaped) * c_mask_shaped_tf))\n",
    "    \n",
    "#     cost = self.cost_lsq + self.cost_reg\n",
    "    cost = cost_lsq\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def popvec(y):\n",
    "    \"\"\"Population vector read out.\n",
    "\n",
    "    Assuming the last dimension is the dimension to be collapsed\n",
    "\n",
    "    Args:\n",
    "        y: population output on a ring network. Numpy array (Batch, Units)\n",
    "\n",
    "    Returns:\n",
    "        Readout locations: Numpy array (Batch,)\n",
    "    \"\"\"\n",
    "    pref = np.arange(0, 2*np.pi, 2*np.pi/y.shape[-1])  # preferences\n",
    "    temp_sum = y.sum(axis=-1)\n",
    "    temp_cos = np.sum(y*np.cos(pref), axis=-1)/temp_sum\n",
    "    temp_sin = np.sum(y*np.sin(pref), axis=-1)/temp_sum\n",
    "    loc = np.arctan2(temp_sin, temp_cos)\n",
    "    return np.mod(loc, 2*np.pi)\n",
    "\n",
    "def custom_response_accuracy(y_true, y_hat):\n",
    "    if type(y_true) is not np.ndarray:\n",
    "        y_true = y_true.numpy()\n",
    "    if type(y_hat) is not np.ndarray:\n",
    "        y_hat = y_hat.numpy()\n",
    "    y_hat_loc1 = popvec(np.mean(y_hat[:, 155:180, 1:], axis=1))\n",
    "    y_true_loc1 = popvec(np.mean(y_true[:, 155:180, 1:], axis=1))\n",
    "    original_dist1 = y_true_loc1 - y_hat_loc1\n",
    "    dist1 = np.minimum(abs(original_dist1), 2*np.pi-abs(original_dist1))\n",
    "    corr_loc1 = dist1 < 2*np.pi/hp['n_loc']\n",
    "\n",
    "    y_hat_loc2 = popvec(np.mean(y_hat[:, 180:, 1:], axis=1))\n",
    "    y_true_loc2 = popvec(np.mean(y_true[:, 180:, 1:], axis=1))\n",
    "    original_dist2 = y_true_loc2 - y_hat_loc2\n",
    "    dist2 = np.minimum(abs(original_dist2), 2*np.pi-abs(original_dist2))\n",
    "    corr_loc2 = dist2 < 2*np.pi/hp['n_loc']\n",
    "    \n",
    "    return np.sum(corr_loc1*0.5+corr_loc2*0.5)/corr_loc1.shape[0]\n",
    "\n",
    "def custom_response_loss(y_true, y_hat):\n",
    "    if type(y_true) is not np.ndarray:\n",
    "        y_true = y_true.numpy()\n",
    "    if type(y_hat) is not np.ndarray:\n",
    "        y_hat = y_hat.numpy()\n",
    "    y_hat_loc1 = popvec(np.mean(y_hat[:, 155:180, 1:], axis=1))\n",
    "    y_true_loc1 = popvec(np.mean(y_true[:, 155:180, 1:], axis=1))\n",
    "    original_dist1 = y_true_loc1 - y_hat_loc1\n",
    "    dist1 = np.minimum(abs(original_dist1), 2*np.pi-abs(original_dist1))\n",
    "\n",
    "    y_hat_loc2 = popvec(np.mean(y_hat[:, 180:, 1:], axis=1))\n",
    "    y_true_loc2 = popvec(np.mean(y_true[:, 180:, 1:], axis=1))\n",
    "    original_dist2 = y_true_loc2 - y_hat_loc2\n",
    "    dist2 = np.minimum(abs(original_dist2), 2*np.pi-abs(original_dist2))\n",
    "    \n",
    "    return np.sum(dist1*0.5+dist2*0.5)/dist1.shape[0]*(360/(2*np.pi))\n",
    "\n",
    "def custom_perf(y_true, y_hat):\n",
    "\n",
    "    if type(y_true) is not np.ndarray:\n",
    "        y_true = y_true.numpy()\n",
    "    if type(y_hat) is not np.ndarray:\n",
    "        y_hat = y_hat.numpy()\n",
    "\n",
    "    y_true = y_true[:,-1,:]\n",
    "    y_hat = y_hat[:,-1,:]\n",
    "\n",
    "    y_hat_loc = popvec(y_hat[..., 1:])\n",
    "    y_true_loc = popvec(y_true[..., 1:])\n",
    "    y_hat_fix = y_hat[..., 0]\n",
    "    fixating = y_hat_fix > 0.5 \n",
    "\n",
    "    original_dist = y_true_loc - y_hat_loc\n",
    "    dist = np.minimum(abs(original_dist), 2*np.pi-abs(original_dist))\n",
    "    corr_loc = dist < 2*np.pi/hp['n_loc']\n",
    "\n",
    "\n",
    "    # Should fixate?\n",
    "    should_fix = y_true_loc < 0\n",
    "\n",
    "    # performance\n",
    "    perf = should_fix * fixating + (1-should_fix) * corr_loc * (1-fixating) \n",
    "    return np.mean(perf)\n",
    "# In[83]:\n",
    "\n",
    "def generate_trial(mode='random',batch_size=hp['batch_size_train'],**kwargs):\n",
    "    dt = hp['dt']\n",
    "    if mode == 'random':\n",
    "        rng = hp['rng']\n",
    "        # stim_dist = rng.uniform(0.25*np.pi, 1.75*np.pi,(batch_size,))*rng.choice([-1,1],(batch_size,))\n",
    "        # batch_size = 1\n",
    "        stim1_locs = rng.uniform(0, 2*np.pi, (batch_size,))\n",
    "        stim2_locs = rng.uniform(0, 2*np.pi, (batch_size,))\n",
    "\n",
    "        stims_mean = rng.uniform(0.8,1.2,(batch_size,))\n",
    "        stims_coh  = rng.choice([0.,0.08,0.16,0.32],(batch_size,))\n",
    "        stims_sign = rng.choice([1,-1], (batch_size,))\n",
    "\n",
    "        stim1_strengths = stims_mean + stims_coh*stims_sign\n",
    "        stim2_strengths = stims_mean - stims_coh*stims_sign\n",
    "\n",
    "    elif mode == 'fixed':\n",
    "        n_loc = kwargs['n_loc']\n",
    "        batch_size = n_loc*n_loc\n",
    "        n_stim_loc1, n_stim_loc2, repeat = stim_loc_shape = n_loc, n_loc, 1\n",
    "        stim_loc_size = np.prod(stim_loc_shape)\n",
    "        ind_stim_loc1, ind_stim_loc2, ind_repeat = np.unravel_index(range(stim_loc_size),stim_loc_shape)\n",
    "        stim1_locs = 2*np.pi*ind_stim_loc1/n_stim_loc1\n",
    "        stim2_locs = 2*np.pi*ind_stim_loc2/n_stim_loc2\n",
    "        \n",
    "        stim1_strengths = 1\n",
    "        stim2_strengths = 1\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Unknown mode: ' + str(mode))\n",
    "        \n",
    "    stim1_ons = int(500/dt)\n",
    "    stim1_offs = stim1_ons + int(300/dt)\n",
    "    stim2_ons =stim1_offs + int(1000/dt)\n",
    "    stim2_offs = stim2_ons + int(300/dt)\n",
    "    fix_offs  = stim2_offs + int(1000/dt)\n",
    "    output_2_on = fix_offs + int(500/dt)\n",
    "    tdim = output_2_on + int(500/dt)\n",
    "\n",
    "    check_ons = fix_offs + int(100/dt)\n",
    "\n",
    "    trial = Trial(hp, tdim, batch_size)\n",
    "    trial.add('fix_in', offs=fix_offs)\n",
    "    trial.add('stim', stim1_locs, ons=stim1_ons, offs=stim1_offs, strengths=stim1_strengths, mods=1)\n",
    "    trial.add('stim', stim2_locs, ons=stim2_ons, offs=stim2_offs, strengths=stim2_strengths, mods=1)\n",
    "    trial.add('fix_out', offs=fix_offs)\n",
    "    stim_locs = [stim1_locs[i] for i in range(batch_size)]\n",
    "    stim_locs2 = [stim2_locs[i] for i in range(batch_size)]\n",
    "    trial.add('out',stim_locs,ons=fix_offs,offs=output_2_on)\n",
    "    trial.add('out',stim_locs2,ons=output_2_on)\n",
    "\n",
    "    trial.add_c_mask(pre_offs=fix_offs,post_ons=check_ons)\n",
    "    trial.epochs = {'fix1':(None,stim1_ons),\n",
    "                    'stim1':(stim1_ons,stim1_offs),\n",
    "                    'delay1':(stim1_offs,stim2_ons),\n",
    "                    'stim2':(stim2_ons,stim2_offs),\n",
    "                    'delay2':(stim2_offs,fix_offs),\n",
    "                    'go1':(fix_offs,output_2_on),\n",
    "                    'go2':(output_2_on,None)}\n",
    "    return trial\n",
    "\n",
    "def train_generator():\n",
    "    for i in range(hp['steps_per_epoch']*hp['n_epochs']):\n",
    "        trial = generate_trial(mode='random',batch_size=hp['batch_size_train'])\n",
    "        x = trial.x.swapaxes(0,1)\n",
    "        y = trial.y.swapaxes(0,1)\n",
    "        yield x, y\n",
    "\n",
    "def val_generator():\n",
    "    for i in range(hp['steps_per_epoch']*hp['n_epochs']):\n",
    "        trial = generate_trial(mode='random',batch_size=hp['batch_size_val'])\n",
    "        x = trial.x.swapaxes(0,1)\n",
    "        y = trial.y.swapaxes(0,1)\n",
    "        yield x, y\n",
    "\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "\n",
    "def create_model(rnn_layer):\n",
    "    model = Sequential()\n",
    "    model.add(rnn_layer)\n",
    "    model.add(TimeDistributed(Dense(33, activation='sigmoid')))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp['learning_rate']),\n",
    "        loss=custom_mse,\n",
    "        metrics=[custom_perf, custom_response_accuracy,custom_response_loss],\n",
    "        run_eagerly=True)\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp['learning_rate']),\n",
    "    #     loss=custom_mse,\n",
    "    #     metrics=[custom_perf],\n",
    "    #     run_eagerly=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "\n",
    "\n",
    "def generate_hidden_layer_plots(rnn_layer, superscript):\n",
    "    hidden = rnn_layer(x)\n",
    "\n",
    "    for delay in range(1,3):\n",
    "        print('delay:%s'%delay)\n",
    "        delay_bins = get_delay_bins(delay=delay)\n",
    "        #extract mean firing rates for delay bins\n",
    "        delay_hidden = np.mean(hidden[:, delay_bins[0]:delay_bins[1], :], axis=1)\n",
    "    #     delay_hidden = hidden[:, delay_bins[1], :]\n",
    "        plot_tuning_curves(delay_hidden,tuning_curve_folder,'%s_delay%d_hidden'%(superscript,delay))\n",
    "\n",
    "        proj = fit_isomap(data_to_use=delay_hidden)\n",
    "        plot_all_isomap_figures(proj,isomap_folder,'%s_delay%d_hidden'%(superscript,delay))\n",
    "\n",
    "def save_hp(hp, model_dir):\n",
    "    \"\"\"Save the hyper-parameter file of model save_name\"\"\"\n",
    "    hp_copy = hp.copy()\n",
    "    hp_copy.pop('rng', None)\n",
    "    # hp_copy.pop('rng')  # rng can not be serialized\n",
    "    with open(os.path.join(model_dir, 'hp.json'), 'w') as f:\n",
    "        json.dump(hp_copy, f)\n",
    "\n",
    "class NBatchLogger(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A Logger that log average performance per `display` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, display):\n",
    "        self.step = 0\n",
    "        self.display = display\n",
    "        self.metric_cache = {}\n",
    "        self.t_start = time.time()\n",
    "        \n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        keys = list(logs.keys())\n",
    "        for k in keys:\n",
    "            self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
    "        if self.step % self.display == 0:\n",
    "            metrics_log = ''\n",
    "            for (k, v) in self.metric_cache.items():\n",
    "                val = v / self.display\n",
    "                if abs(val) > 1e-3:\n",
    "                    metrics_log += ' - %s: %.4f' % (k, val)\n",
    "                else:\n",
    "                    metrics_log += ' - %s: %.4e' % (k, val)\n",
    "            print('time: {} | trial: {} | batch: {} ... {}'.format(time.time()-self.t_start, self.step * hp['batch_size_train'], self.step,\n",
    "                                          metrics_log))\n",
    "            self.metric_cache.clear()\n",
    "        self.step += 1\n",
    "\n",
    "class AccuracyThresholdCallback(tf.keras.callbacks.Callback): \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        acc = logs.get('custom_response_accuracy')\n",
    "        if(acc > hp['accuracy_threshold']):\n",
    "            print(\"\\nReached %2.2f%% accuracy!\" %(acc*100))   \n",
    "            self.model.stop_training = True\n",
    "\n",
    "class printeverybatch(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        tf.print('train batch:')\n",
    "        tf.print(x[0,90:105,0])\n",
    "        tf.print(y[0,180:,0])\n",
    "        tf.print()\n",
    "        tf.print(x[0,90:105,1])\n",
    "        tf.print(y[0,180:,1])\n",
    "        return super().train_step(data)\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        tf.print('val batch:')\n",
    "        tf.print(x[0,90:105,0])\n",
    "        tf.print(y[0,180:,0])\n",
    "        tf.print()\n",
    "        tf.print(x[0,90:105,1])\n",
    "        tf.print(y[0,180:,1])\n",
    "        return super().test_step(data)\n",
    "# In[108]:\n",
    "\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser(\"HP for training\")\n",
    "#     parser.add_argument(\"--seed\",type=int,default = 0, help = \"Seed number\")\n",
    "#     parser.add_argument(\"--n_rnn\",type=int,default = 256, help = \"Number of hidden neurons\")\n",
    "#     parser.add_argument(\"--batch_size_train\",type=int,default = 512, help = \"Training Batch Size\")\n",
    "#     parser.add_argument(\"--accuracy_threshold\",type=float,default = 0.9, help = \"Accuracy Threshold To Stop Training\")\n",
    "#     parser.add_argument(\"--with_noise\",type=str,default = 'True', help = \"Whether to add input and recurrent noise\",choices=('True','False'))\n",
    "#     parser.add_argument(\"--load_model\",type=str,default = 'False', help = \"Whether to load model\",choices=('True','False'))\n",
    "\n",
    "#     return parser.parse_args()\n",
    "\n",
    "# arglist = parse_args()\n",
    "# seed = arglist.seed\n",
    "# n_rnn = arglist.n_rnn\n",
    "# batch_size_train = arglist.batch_size_train\n",
    "# accuracy_threshold = arglist.accuracy_threshold\n",
    "# with_noise = arglist.with_noise == 'True'\n",
    "# load_model = arglist.load_model == 'True'\n",
    "\n",
    "seed = 7\n",
    "n_rnn = 256\n",
    "# batch_size_train = 512\n",
    "# accuracy_threshold = 0.95\n",
    "# with_noise = True\n",
    "\n",
    "hp['n_rnn']=n_rnn\n",
    "# hp['batch_size_train']=batch_size_train\n",
    "# hp['batch_size_val']=batch_size_train\n",
    "# hp['accuracy_threshold']=accuracy_threshold\n",
    "# hp['n_epochs']=int(100000000/batch_size_train)\n",
    "# hp['n_display']=int(32000/batch_size_train)\n",
    "# hp['n_patience']=hp['n_display']*100\n",
    "hp['seed']=seed\n",
    "hp['rng'] = np.random.RandomState(seed)\n",
    "\n",
    "# print(f\"seed: {seed}, n_rnn: {n_rnn}, batch_size_train: {batch_size_train}, accuracy_threshold: {accuracy_threshold}, n_rnn: {n_rnn}\")\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# trial = generate_trial(mode='fixed',n_loc=hp['n_loc'])\n",
    "# x = trial.x.swapaxes(0,1)\n",
    "# y = trial.y.swapaxes(0,1)\n",
    "# print('x shape: ' + str(x.shape))\n",
    "\n",
    "# c_mask_shaped = get_c_mask((hp['batch_size_train'], x.shape[1], x.shape[2]))\n",
    "# c_mask_shaped_tf = tf.convert_to_tensor(c_mask_shaped, dtype=tf.float32)\n",
    "\n",
    "# model_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_%s_n_hidden_%s_acc_%s_seed_%s'%(batch_size_train,n_rnn,int(accuracy_threshold*100),seed)\n",
    "# if with_noise:\n",
    "#     hp['sigma_rec']=0.05\n",
    "#     hp['sigma_x']=0.01\n",
    "#     model_folder += '_with_noise'\n",
    "# else:\n",
    "#     model_folder += '_no_noise'\n",
    "# print('model folder: ' + model_folder)\n",
    "\n",
    "# main_checkpoint_path = os.path.dirname(model_folder)+\"/checkpoint_seed_%s/cp.ckpt\"%seed\n",
    "# checkpoint_path = model_folder+\"/checkpoint/cp.ckpt\"\n",
    "# isomap_folder = model_folder+'/isomap/'\n",
    "# tuning_curve_folder = model_folder+'/tuning_curves/'\n",
    "# loss_curve_folder = model_folder+'/'\n",
    "\n",
    "# if not os.path.exists(model_folder):\n",
    "#     os.makedirs(model_folder)\n",
    "#     os.makedirs(tuning_curve_folder)\n",
    "#     os.makedirs(isomap_folder)\n",
    "\n",
    "# save_hp(hp, model_folder)\n",
    "# Display hp\n",
    "# for key, val in hp.items():\n",
    "#     print('{:20s} = '.format(key) + str(val))\n",
    "\n",
    "# dataset_train = tf.data.Dataset.from_generator(train_generator, \n",
    "#                                 output_types=(np.float32,np.float32), \n",
    "#                                 output_shapes=((hp['batch_size_train'],x.shape[1],x.shape[2]),(hp['batch_size_train'],y.shape[1],y.shape[2])))\n",
    "# dataset_val = tf.data.Dataset.from_generator(val_generator,\n",
    "#                                 output_types=(np.float32,np.float32), \n",
    "#                                 output_shapes=((hp['batch_size_val'],x.shape[1],x.shape[2]),(hp['batch_size_val'],y.shape[1],y.shape[2])))\n",
    "\n",
    "# cell = LeakyRNNCell2(hp)\n",
    "# rnn_layer = tf.keras.layers.RNN(cell,input_shape=((x.shape[1],x.shape[2])),\n",
    "#                                 return_sequences=True)\n",
    "\n",
    "# print('generating untrained plots......')\n",
    "# generate_hidden_layer_plots(rnn_layer, superscript='untrained')\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "# with strategy.scope():\n",
    "#     model = create_model(rnn_layer)\n",
    "\n",
    "# model = create_model(rnn_layer)\n",
    "# print(os.path.dirname(main_checkpoint_path))\n",
    "# print(load_model)\n",
    "# print(os.path.exists(os.path.dirname(main_checkpoint_path)))\n",
    "# if load_model and os.path.exists(os.path.dirname(main_checkpoint_path)):\n",
    "#     print('loading previous model......')\n",
    "#     model.load_weights(main_checkpoint_path)\n",
    "# existing_model = create_model(rnn_layer)\n",
    "# model=printeverybatch(existing_model.input,existing_model.output)\n",
    "# model.compile(optimizer=existing_model.optimizer,loss=existing_model.loss)\n",
    "# model.summary()\n",
    "\n",
    "# options = tf.data.Options()\n",
    "# options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "# dataset_train = dataset_train.with_options(options)\n",
    "# dataset_val = dataset_val.with_options(options)\n",
    "\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# performance_dict = {}\n",
    "# performance_dict['untrained accuracy on %s trials'%x.shape[0]] = round(custom_response_accuracy(y, model.predict(x)),4)\n",
    "# performance_dict['untrained loss on %s trials'%x.shape[0]] = round(custom_response_loss(y, model.predict(x)),4)\n",
    "# performance_dict['untrained perf on %s trials'%x.shape[0]] = round(custom_perf(y, model.predict(x)),4)\n",
    "# print(performance_dict)\n",
    "\n",
    "# display_callback = NBatchLogger(display=hp['n_display'])\n",
    "# threshold_callback = AccuracyThresholdCallback()\n",
    "# history_logger_callback = tf.keras.callbacks.CSVLogger(loss_curve_folder+'log.csv', separator=\",\", append=True)\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                 save_weights_only=True,\n",
    "#                                                 save_best_only=True,\n",
    "#                                                 monitor='loss',\n",
    "#                                                 verbose=0)\n",
    "# es_callback = tf.keras.callbacks.EarlyStopping(restore_best_weights=True, \n",
    "#                                                 patience=hp['n_patience'],\n",
    "#                                                 monitor='loss')\n",
    "\n",
    "# history = model.fit(dataset_train, epochs=hp['n_epochs'], steps_per_epoch=hp['steps_per_epoch'], verbose=0,\n",
    "#           callbacks=[cp_callback, history_logger_callback, display_callback, threshold_callback])\n",
    "\n",
    "# shutil.copytree(os.path.dirname(checkpoint_path), os.path.dirname(main_checkpoint_path), dirs_exist_ok=True)\n",
    "\n",
    "# plot_loss_over_epochs(history, foldername=loss_curve_folder)\n",
    "\n",
    "# model = create_model(rnn_layer)\n",
    "# model.load_weights(checkpoint_path)\n",
    "# rnn_layer = tf.keras.layers.RNN(cell,input_shape=((x.shape[1],x.shape[2])),\n",
    "#                                 return_sequences=True, weights=model.layers[0].get_weights())\n",
    "# print('generating trained plots......')\n",
    "# generate_hidden_layer_plots(rnn_layer, superscript='trained')\n",
    "\n",
    "# performance_dict['trained accuracy on %s trials'%x.shape[0]] = round(custom_response_accuracy(y, model.predict(x)),4)\n",
    "# performance_dict['trained loss on %s trials'%x.shape[0]] = round(custom_response_loss(y, model.predict(x)),4)\n",
    "# performance_dict['trained perf on %s trials'%x.shape[0]] = round(custom_perf(y, model.predict(x)),4)\n",
    "# print(performance_dict)\n",
    "\n",
    "# with open(os.path.join(model_folder, 'performance.json'), 'w') as f:\n",
    "#     json.dump(performance_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305a0b3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m n_loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      3\u001b[0m n_stim_loc1, n_stim_loc2, repeat \u001b[38;5;241m=\u001b[39m stim_loc_shape \u001b[38;5;241m=\u001b[39m n_loc, n_loc, \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m stim_loc_size \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mprod(stim_loc_shape)\n\u001b[1;32m      5\u001b[0m ind_stim_loc1, ind_stim_loc2, ind_repeat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munravel_index(\u001b[38;5;28mrange\u001b[39m(stim_loc_size),stim_loc_shape)\n\u001b[1;32m      6\u001b[0m stim1_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39mind_stim_loc1\u001b[38;5;241m/\u001b[39mn_stim_loc1\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "n_loc=8\n",
    "\n",
    "n_stim_loc1, n_stim_loc2, repeat = stim_loc_shape = n_loc, n_loc, 1\n",
    "stim_loc_size = np.prod(stim_loc_shape)\n",
    "ind_stim_loc1, ind_stim_loc2, ind_repeat = np.unravel_index(range(stim_loc_size),stim_loc_shape)\n",
    "stim1_locs = 2*np.pi*ind_stim_loc1/n_stim_loc1\n",
    "stim2_locs = 2*np.pi*ind_stim_loc2/n_stim_loc2\n",
    "\n",
    "trial = generate_trial(mode='fixed',n_loc=hp['n_loc'])\n",
    "x = trial.x.swapaxes(0,1)\n",
    "y = trial.y.swapaxes(0,1)\n",
    "print('x shape: ' + str(x.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d5db8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n = []\n",
    "for i in range(stim_loc_size):\n",
    "    for j in range(10):\n",
    "        X_n.append(x[i] + hp['rng'].randn(205, 33)*0.01)\n",
    "X_n = np.array(X_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2593ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "generating_hidden layer\n",
      "done\n",
      "delay:2\n"
     ]
    }
   ],
   "source": [
    "for acc in [95]:\n",
    "    destination_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_512/n_hidden_256/weight_matrix/acc_%s'%acc\n",
    "    for i in range(1,2):\n",
    "        model_folder = '/Users/lowxizhi/Documents/fyp/codes/results/2_stim_batch_size_512/n_hidden_256/2_stim_batch_size_512_n_hidden_256_acc_%s_seed_%s_with_noise'%(acc,i)\n",
    "        checkpoint_path = model_folder+\"/checkpoint/cp.ckpt\"\n",
    "        isomap_folder = model_folder+'/isomap'\n",
    "        isomap_stim1_file = isomap_folder+'/trained_delay2_hidden_target_isomap.png'\n",
    "        if os.path.exists(isomap_stim1_file):\n",
    "            \n",
    "            cell = LeakyRNNCell2(hp)\n",
    "            rnn_layer = tf.keras.layers.RNN(cell,input_shape=((x.shape[1],x.shape[2])),\n",
    "                                            return_sequences=True)\n",
    "            model = create_model(rnn_layer)\n",
    "            model.load_weights(checkpoint_path)\n",
    "            rnn_layer = tf.keras.layers.RNN(cell,input_shape=((x.shape[1],x.shape[2])),\n",
    "                                            return_sequences=True, weights=model.layers[0].get_weights())\n",
    "            \n",
    "            print('generating_hidden layer')\n",
    "            hidden = rnn_layer(X_n)\n",
    "            print('done')\n",
    "            for delay in range(2,3):\n",
    "                print('delay:%s'%delay)\n",
    "                delay_bins = get_delay_bins(delay=delay)\n",
    "                #extract mean firing rates for delay bins\n",
    "                delay_hidden = np.mean(hidden[:, delay_bins[0]:delay_bins[1], :], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73eea61b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind_stim_loc1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mind_stim_loc1\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ind_stim_loc1' is not defined"
     ]
    }
   ],
   "source": [
    "ind_stim_loc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "88748d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_stim</th>\n",
       "      <th>second_stim</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.207737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.211232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.190090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.208555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.194395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_stim  second_stim  activity\n",
       "0             0            0  0.030912\n",
       "1             0            0  0.030322\n",
       "2             0            0  0.030527\n",
       "3             0            0  0.030091\n",
       "4             0            0  0.030816\n",
       "..          ...          ...       ...\n",
       "635           7            7  1.207737\n",
       "636           7            7  1.211232\n",
       "637           7            7  1.190090\n",
       "638           7            7  1.208555\n",
       "639           7            7  1.194395\n",
       "\n",
       "[640 rows x 3 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron = 0\n",
    "Z=delay_hidden\n",
    "df = pd.DataFrame({'first_stim':np.array([[i]*10 for i in ind_stim_loc1]).flatten(),'second_stim':np.array([[i]*10 for i in ind_stim_loc2]).flatten(),'activity':Z[:,neuron]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "55a99931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Source         SS   DF        MS              F  p-unc  \\\n",
      "0                first_stim  59.352914    7  8.478988  137141.220962    0.0   \n",
      "1               second_stim   1.196443    7  0.170920    2764.509576    0.0   \n",
      "2  first_stim * second_stim   2.252036   49  0.045960     743.366934    0.0   \n",
      "3                  Residual   0.035612  576  0.000062            NaN    NaN   \n",
      "\n",
      "        np2  \n",
      "0  0.999400  \n",
      "1  0.971095  \n",
      "2  0.984433  \n",
      "3       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lowxizhi/miniforge3/envs/tf_env/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.0, the latest is 0.5.1.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pingouin as pg\n",
    "aov = pg.anova(dv='activity', between=['first_stim', 'second_stim'], data=df,\n",
    "             detailed=True)\n",
    "\n",
    "print(aov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be3a7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For statistics. Requires statsmodels 5.0 or more\n",
    "import statsmodels.api as sm\n",
    "# Analysis of Variance (ANOVA) on linear models\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ffaa7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['activity']\n",
    "X = df[['first_stim','second_stim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "968bca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:               activity   R-squared (uncentered):                   0.702\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.701\n",
      "Method:                 Least Squares   F-statistic:                              751.1\n",
      "Date:                Mon, 28 Feb 2022   Prob (F-statistic):                   2.12e-168\n",
      "Time:                        14:16:24   Log-Likelihood:                          97.170\n",
      "No. Observations:                 640   AIC:                                     -190.3\n",
      "Df Residuals:                     638   BIC:                                     -181.4\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "first_stim      0.0819      0.003     29.737      0.000       0.077       0.087\n",
      "second_stim    -0.0084      0.003     -3.064      0.002      -0.014      -0.003\n",
      "==============================================================================\n",
      "Omnibus:                      204.550   Durbin-Watson:                   0.010\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              517.605\n",
      "Skew:                           1.650   Prob(JB):                    4.01e-113\n",
      "Kurtosis:                       5.919   Cond. No.                         2.38\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d4b2618a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PandasData' object has no attribute 'design_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [122]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Peform analysis of variance on fitted linear model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m anova_results \u001b[38;5;241m=\u001b[39m \u001b[43manova_lm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mANOVA results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(anova_results)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.8/site-packages/statsmodels/stats/anova.py:349\u001b[0m, in \u001b[0;36manova_lm\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    348\u001b[0m     model \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43manova_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple models only supported for type I. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(typ))\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.8/site-packages/statsmodels/stats/anova.py:66\u001b[0m, in \u001b[0;36manova_single\u001b[0;34m(model, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m nobs \u001b[38;5;241m=\u001b[39m exog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     65\u001b[0m response_name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mendog_names\n\u001b[0;32m---> 66\u001b[0m design_info \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesign_info\u001b[49m\n\u001b[1;32m     67\u001b[0m exog_names \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mexog_names\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# +1 for resids\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PandasData' object has no attribute 'design_info'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Peform analysis of variance on fitted linear model\n",
    "anova_results = anova_lm(model)\n",
    "print('\\nANOVA results')\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0c9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
